## HTTP/3
- 运行在QUIC之上的HTTP被称为http/3(HTTP over QUIC)
- QUIC协议（quick UDP Internect Connection）基于UDP协议，正是看中了UDP的速度与效率，同时QUIC也整合了TCP、TLS和HTTP/2的优点，并加以优化
- 特点
  - 减少了握手的延迟（1-RTT或者0-RTT）RTT（往返时间）
  - 多路复用，并且没有TCP阻塞问题
  - 连接迁移，（主要是在客户端），当由wifi转移到4g的时候，连接不会被断开
- HTTP3跟HTTP/1.1和HTTP/2没有直接的关系
### HTTP/3之QUIC


[好文章](https://blog.csdn.net/LuckyWinty/article/details/106678662)

#### 0RTT建立连接
RTT（往返时间）
HTTP/3首次连接需要的时间是1RTT,后续传输只需要0RTT,意味着客户端发送给服务端的第一个包就带有请求数据
1. 首次连接，客户端发送`Inchoate Client Hello`给服务端，用于请求连接
2. 服务其返回Server Config在发送Rejection消息给客户端
3. client会将加密HTTP数据，发送给server
4. 服务端收到请求，解密数据，ServerHello
可以看到`QUIC`从请求连接到正式接发HTTP数据一共花了1RTT,这一个RTT主要是为了获取`Server Config`后面的连接如果缓存了`Server COnfig`，那么就可以直接发送HTTP数据，实现0RTT建立连接.

#### 连接迁移
TCP连接基于四元组（源Ip、源端口、目的IP、目的端口）,切换网络时，至少会有一个因素发生变化，导致连接发生变化，当连接发生变化时，如果还是用原来的TCP连接，则会导致连接失败，就得等原来得连接超时后重新连接，所以我们有时候发现切换到一个新得网络时，即使新网络状态良好，但内容还是要加载很慢

QUIC得连接不受四元组得影响，当这个元素发生变化，原链接依然能够维持，因为QUIC以64随机数作为`ConnectionID`

#### 队首堵塞比较

> 就是需要排队，队首的事情没有处理完的时候，后面的人都要等着

http1.0的队首堵塞
> 对于同一个TCP连接，所有的http1.0请求放入队列中，只有一个请求的响应收到了，才会发送下一个请求，可见http1.0队首阻塞发生在客户端

http1.1的队首堵塞

> 对于同一个tcp连接，http1.1允许一次性发送多个http1.1请求，也就是说不必等前一个响应收到，就可以发送下一个请求，这样就解决了客户端的队首阻塞，但是http1.1规定，服务器端的响应的发送要根据请求被接收的顺序排队，也就是说，先接收到请求，响应也要先发送，如果最先收到的请求处理时间长，响应时间慢（或者请求发生丢失，需要重传），就会堵塞后面的请求，只能等待第四个请求处理完毕才能被处理

http2队首阻塞

 http/2每个请求都会被拆分成多个Frame(骨架)，然后不同的Frame组成不同的请求，Frame是TCP传输的单位，这样的话，HTTP/2就达到了一条连接同事发送多条请求的目标，这就是多路复用的原理。如果在一条TCP连接上同事发送了4个stream,其中Stream1已经正确送达，Stream2的第三个Frame丢失，TCP处理数据时有严格的前后顺序，先发送的要先被处理，这样就会让重传第三个Frame,Stream3和Stream4虽然说已经到了，但是不能被处理，那么这个时候这个键连接都会被堵塞

HTTP/2的多路虽然可以解决`请求`这个粒度的堵塞，但HTTP/2的基础TCP协议本身也存在着队首堵塞的问题

- 由于HTTP/2必须使用HTTPS,而 HTTPS 使用的 TLS 协议也存在队头阻塞问题。TLS 基于 Record 组织数据，将一堆数据放在一起（即一个 Record）加密，加密完后又拆分成多个 TCP 包传输。一般每个 Record 16K，包含 12 个 TCP 包，这样如果 12 个 TCP 包中有任何一个包丢失，那么整个 Record 都无法解密

- 队首阻塞会导致HTTP/2在更容易丢包的弱网络环境比HTTP/1.1更慢

QUIC解决队首堵塞的问题的方法
- QUIC的传输单位是Packet,加密单位也是Packet，整个加密传输，解密都基于Packet，这样就能避免TLS的队首堵塞问题
- QUIC基于UDP,UDP的数据包在接收端没有处理顺序，即使中间丢失了一个包，也不会堵塞整条连接，其他资源也能被正常处理
#### 拥塞控制，QUIC与TCP基本一致
由于出现了窗口这个东西，TCP发送报文段不是一个一个发送，就可以连续发送大量的数据包了，但是这样问题也出现了，就会出现网络复杂和网络拥堵的问题，TCP为了解决这个问题，就使用了`拥塞控制`，在面临网络拥塞时，就会遏制发送方的数据发送

拥塞控制主要有2种方法
1. 端到端的拥塞控制：因为网络层没有为运输层拥塞控制提供显示支持，所以即使网络中存在拥塞的情况，端系统也要通过网络行为来观察来推断，TCP就是使用了端到端的拥塞控制方法。也就是采用了如果超时或者三次冗余确认就会被认为网络拥塞，TCP会减小窗口的大小或者增加往返耗时来避免
2. 网络辅助的拥塞控制在网络辅助的拥塞控制中，路由器会像发送方提供关于网络中拥塞状态的反馈

当感受到了端到端的拥塞时，一般会遵循3个原则，来选择不同的算法

- 如果在报文段发送过程中丢失，那就意味着网络拥堵，此时需要适当的降低TCP发送方的效率
- 一个确认报文段指示发送方正在向接收方传递报文段，因此，当对先前未接收到确认报文段的确认到达时，能够增加发送方的速率。因为未确认的报文段到达接收方也就相当于网络不拥塞，也就相当于可以顺利到达。
- 带宽检测，带宽检测说的是TCP可以通过调节传输速率来增加/减少ACK到达的次数，如果出现丢包，就会减少传输速率，同样的，如果检测拥塞开始的出现的频率，那么就会慢慢的增加传输效率。然后慢慢是传输速率降低，再次进行探测，看看拥塞开始速率是否发生了变化

**拥塞控制算法1. 慢启动**
发送方向接收方发送 1 个单位的数据，收到对方确认后会发送 2 个单位的数据，然后依次是 4 个、8 个……呈指数级增长，这个过程就是在不断试探网络的拥塞程度，超出阈值则会导致网络拥塞；
**拥塞控制算法2. 拥塞避免**
指数增长不可能是无限的，到达某个限制（慢启动阈值）之后，指数增长变为线性增长；
**拥塞控制算法3. 快速重传**：发送方每一次发送时都会设置一个超时计时器，超时后即认为丢失，需要重发
**拥塞控制算法4. 快速恢复**：在上面快速重传的基础上，发送方重新发送数据时，也会启动一个超时定时器，如果收到确认消息则进入拥塞避免阶段，如果仍然超时，则回到慢启动阶段。

#### 流量控制
流量控制是让发送方不要发送的太快，让接受方能进行接收，TCP的流量控制主要是通过滑动窗口来实现的。


### 例子
X5 内核是腾讯开发的适用于安卓系统的浏览器内核，为了解决传统安卓系统浏览器内核适配成本高、不安全、不稳定等问题而开发的统一的浏览器内核。STGW 是 Secure Tencent Gateway 的缩写，意思是腾讯安全云网关。两者早在前两年便支持了 QUIC 协议