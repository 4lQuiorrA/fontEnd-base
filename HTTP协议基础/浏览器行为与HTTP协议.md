### 输入 url 回车到浏览器展示网站页面处理流程（极简 v0.1）：

1. 输入网址并回车
   进行网络验证，判断网站是否是连通的
2. 解析域名
   访问本地`DNS`服务器， 将人能识别的域名根据本地数据库存储的内容，转化成 ip 地址，这样就知道要访问那个服务器了
3. 浏览器发送 http 请求
   找到了服务器之后，浏览器就能够正式的发送 http 请求了，然后请求走到了反向代理（类似机房）。然后，反向代理在根据代理协议，将这个请求落到某台服务器上。

   这个时候就涉及到发送数据包的过程

4. 如果请求成功了，服务器返回 html
   这是时候，服务器要把响应返回到浏览器端，怎么来的就需要怎么回去，但是可能的是，回的时候走的链路可能不是原来的路了。
   为什么可能不一样的路呢？
   局域网上的设备到服务器，要经过很多路由器，是透明的，正常来说是无感知的，在互联网中，许许多多的路由器组成网，为了网络的健壮性。一个数据的发送需要查找路由表，路由表就会告诉你要先走那个路由，到了一个路由就要继续查找这个路由上的路由表，就会告诉下一个路由的位置，重复这个过程。 就如果一个路由器无法走通，数据可以通过其他路由器，最后经过跳转到达目的地
5. 浏览器处理 html

### TCP/IP 协议栈

| iso/osi 协议 | TCP/IP 协议簇 |
| ------------ | ------------- |
| 应用层       | 应用层        |
| 表示层       |               |
| 会话层       |               |
| 传输层       | 传输层        |
| 网络层       | 网络层        |
| 数据链路层   | 网络接口层    |
| 物理层       |               |

1. 应用层

   > 为用户提供所需要的各种服务，例如：HTTP,FTP,DNS,SMTP

2. 传输层

   > 为应用层实体，提供端到端的通信功能，保证数据包的顺序传送和数据的完整性

3. 网络层
   > 主要解决主机到主机的通信问题，IP 协议是网际互联层最重要的协议
4. 网路接口层
   > 负责监视数据在主机和网路之间交换

**TCP 和 UDP**
[TCP 和 UDP](https://juejin.cn/post/6900710442583359501#heading-18)
UDP (user data protocol)

1. 速度快，采用 UDP 协议时，只要应用程序将数据传给 UDP,UDP 就会将次数据打包进 UDP 报文段并立刻传递给网络层，然后 TCP 有拥塞控制的功能，他会在发送前判断互联网的拥堵情况
2. 无需建立连接，TCP 在数据传输之前需要经过三次握手的操作，而 UDP 则无需任何准备即可进行数据传输。因此 UDP 没有建立连接的实验。TCP 和 UDP 可以比喻成开发：TCP 就是凡事设计好，没有设计就不会开发的工程师，需要把一切因素考虑在内后才能做事！所以这个是靠谱小青年！而 UDP 就是有需求就能干事，不考虑任何影响，这样是非常不靠谱的，但是这样的人适合用于快速开发，容易上手。
3. 无连接状态，在 http1.1 之后增加了`keep-alive`的长连接状态，TCP 连接需要在端对端中维护这个连接状态，连接状态包括接受和发送缓存，拥塞控制参数以及序号和确认好的参数。而在 UDP 中不需要这些参数。因此在专门用于特定应用的服务器当应用程序运行在 UDP 上，一般能支持更多的活跃用户
4. 分组首部，每个 TCP 报文段都有 20 个字节的首部开销，而 UDP 仅仅只有 **8** 字节的开销
   > 这里需要注意一点，并**不是所有**使用 UDP 协议的应用层都是**不可靠的**，应用程序可以自己实现可靠的数据传输，通过增加确认和重传机制。所以使用 UDP 协议最大的特点就是速度快

TCP(transmission Control Protocol 传输控制协议)

1. 全双工服务：即主机 A 和主机 B 连接的时候，应用程序能从主机 A 到主机 B，也能同时从主机 B 到主机 A(半双工：允许两者相互通信，但是不能同时通信。)
2. 点对点连接，TCP 连接只能连接一对主机
3. TCP 会将数据临时存储到连接的发送缓存中（send buffer）中，这个`send buffer`是三次握手之间设置的缓存之一，然后 TCP 在合适的时间将发送缓存中的数据发送到目标主机的接受缓存中，实际上每个端都会有发送缓存和接收缓存

主机在连接中，是以报文段进行的，TCP 会将传输的数据流分为多个块（chunk）,然后向每个 chunk 中添加 TCP 标头，二这样的一个`TCP`段也就是报文段。每个报文段可以传输的长度是有限的，不能超过**最大数据长度**。在报文段向下传输的过程中，会经过链路层，链路层有一个**最大传输单元**。最大传输单元所能通过最大数据包的大小，最大传输单元通常与通信接口相关

由于计算机网络是分层的，同样的`chunk`块
在传输层，加入了 TCP 标识头，这个时候被称为报文段
而在网络层，加入了 IP 表示头，这个时候就被叫做 IP 数据包

#### TCP 的序号和确认号

这两个字段是保证`TCP`实现可靠性的基础
**序号**
一个报文段的序号就是数据流的字节编号，因为`TCP`会把数据流分割成为一段一段的字节流，因为字节流本身是有序的，所以每一段的字节编号就是标示是哪一段的字节流.比如 A 要想 B 发送一条数据。数据经过应用层产生后会有一串数据流，数据流会经过 TCP 分割，分割的依据就是（最大数据长度），加入数据是 10000 字节，最大数据长度为 2000，那么 TCP 就会把数据拆分为`0-1999`,`2000-3999`，依次类推。
所以知道了，第一组数据`0-1999`的首字节编号就是`0`
第二组数据`2000-3999`首字节编号就是`2000`.
当报文段在传输层加入`TCP`标识的时候，那么就会在序号前面加上`0`或者`2000`等。

**确认号 ACK**
这里就涉及到了全双工通信了。也就是 A 接手 B 的数据的时候，同时支持向 B 发送数据。
那么确认号是什么？主机 A 要发送的报文段里面的确认号就是，A 接受到的数据的序号的下一个报文段的序号
也就是说，我这次接受到的是`0-1999`的报文段，那么我要发送给 B 的报文段里面的确认号就是`2000`，因为`A`期望接收到`2000`以后的数据，所以报文段里面的`确认号`就是`2000`

到 B 发送了一部分数据之后，接收到了来自`A`的`ACK`，那么证明数据已经到达了 A。反之就认为数据可能丢失，等待一段时间，仍然没有接收到`ACK`，那么就会认为丢包，进行重发

#### TCP 传输控制

如果 B 向 A 发送了数据，需要 A 返回了确认号，B 才能继续发送后面的报文段。那么这样就会存在性能不够的情况，因为这样传输数据很慢。所以 TCP 引入了窗口这个概念来解决这个问题

1. 也就是每次请求都可以发送多个报文段，也就是说一个窗口可以发送多个报文段。窗口大小就是只无需等待确认应带就可以继续发送报文段的最大值。
2. 在窗口机制中，大量使用了**缓冲区**，通过对多个段同时进行确认应答的功能

如果在传输途中发生了丢包，那么在窗口机制会如何处理？

> 当 A 将数据发送给 B，中间有一个报文段（0-1999）发生了丢失，但是 A 不会等待，会继续发送剩下的报文，但是 B 的确认应答一直是`0`,如果发送端 A 连续 3 次收到了同一个确认应答后，会认为这个**报文段**已经丢失，就会将对应的**报文段**进行重发。这种机制被称为`高速重发控制`，这种重发的确认应答也被成为`冗余ACK响应`

#### TCP 流量控制

在一个 TCP 的连接的两端主机都是有一个`socket缓冲区`（接收缓存和发送缓存），发送方送到数据到接收方的接收缓存，但是我们知道，一个应用执行需要各种资源（分配时间片区执行），所以接收缓存的数据容易溢出
`TCP`有**流量控制服务**用于消除缓冲区溢出的情况。流量控制是一个速度匹配服务，即发送速率与接收方应用程序的读取速率相匹配。
`TCP`通过使用一个**接收窗口（recive window）**的变量来提供流量控制，接收窗口会给发送方一个指示当前还有可用的接收缓存空间。这样发送方就能根据这个接收端的实际接受能力来控制发送数据量。这个可用的接收缓存空间就是存放在`TCP`报文内**接收窗口字**段上发送到发送方
而发送方也会定期发送一个`窗口探测包`，这个包用于探测接收端主机是否还能接收数据。当接收端的缓冲区以但面临数据溢出的风险时，窗口大小的只也会被设置成更小的值通知给发送端，从而控制数据发送量

#### TCP 连接管理

1. 三次握手
   (SYN 同步序列编号) SEQ(序列号)

- 首先，客户端先向服务器发送一个特殊的`tcp报文段`，这个报文段首部不包含应用层数据，但是在报文段的首部有个`SYN标志位`被置为 1，因此，这个特殊的报文段也可以叫做`SYN`报文段。然后，客户端随机选择一个`初始序列号（client_isn）`,并将此数字放入初始`TCP SYN`段的序列号字段中，紧接着这个报文段有发送到网络层，被封装在 IP 数据段中发送给服务器
- 一旦包含 IP 数据段到达服务器后，服务器在运输层中提取了`TCP SYN`段，然后给这个连接分配了缓冲区和变量，接着给客户端发送一个连接允许的报文段。这个连接所允许的报文段也不包括任何应用层数据，除了 3 个信息
  - 首先，`SYN`被置为`1`
  - 然后，TCP 报文段的首部确认号被设置位`client_isn+1`
  - 最后，服务器选择自己的初始序号（`server_isn`）,并将其放置到`TCP`报文段首部的序号字段中
    **在这个过程中，最容易收到 DDOS（分布式 DOS 攻击） 和 DOS(deny of Server) 攻击**
  - 在收到`SYN ACK`报文段后，客户端也要位该连接分配缓冲区和变量，客户端主机向服务其发送另外一个报文段。最后一个报文段对服务其发送的响应报文做了确认，确认的标准是客户端发送的数据段确认号`server_isn+1`因为连接已经建立了，所以`SYN 位`被置为 `0`

2. 四次挥手
数据传输结束之后。就能进入释放连接的时候
- 客户端应用程序发出释放连接的报文段，并停止发送数据，主动关闭TCP连接，客户端主机发送释放连接的报文段，报文段中首部`FIN`位置呗置为1，不包含数据，序列号位seq=u,此时客户端主机进入`FIN-wait-1`阶段
- 服务器主机接收到客户端发出的报文段后，即发出确认应答报文，确认报文中ACK=1,生成自己的序号位，seq=v,ack=u+1.然后服务器主机就进入`CLOSE-WAIT(关闭等待状态)`，这个时候**客户端到服务端这条路就断了，这个时候客户端没有什么数据需要发送给服务器了，但是服务器属于一个半连接状态，服务器主机可以接着将剩下的数据发送完毕**
- 客户端主机收到服务端主机的应答后，即进入`FIN-WAIT-2`，等待服务端发送连接释放的报文段。
- 当服务器没有数据发送后，应用程序就会通知TCP释放连接，这是服务器主机会发出断开连接的报文段，报文段中ACK=1,序列号seq=w。因为这时候可能以及发送一些数据所以seq不一定等于v+1，ack=u+1,在发送完断开请求的报文之后，服务端主机就进入了**LAST-ACK最后确认状态**的阶段
- 客户端收到服务端的断开链接请求后，客户端需要做出响应，客户端发出断开连接的报文段，在报文段ACK位为1，序列号seq=u+1，因为客户端从连接开始断开后就没发送过数据，ack=w+1,然后进入到`TIME-Wait`状态，**这个时候TCP连接还没有释放，必须经过时间等待的设置，也就是2MSL后，客户端才会进入CLOSE状态，时间MSL也叫最长报文寿命**
- 服务端收到了客户端的断开连接就会进入**CLOSE状态**

问题Q:什么是`TIME-WAIT`
MSL（最大报文存活寿命）是TCP报文段可以存活或者驻留在网络中的最长时间。RFC793定义了2分钟的时长，但是一般实现是采用了30s的最大存活时间
那么为什么在这里要等待2MSL?
1. 为了保证最后一个响应能达到服务器，因为在计算机网络中，如果最后一个ACK报文段发生了丢失，就会让服务器一直处于**LAST-ACK**状态。这个时候服务器会重传一次**FIN ACK**断开连接，客户端接收后，在进行重新确认关闭，**重启定时器**。如果不是2MSL的话，一旦在客户端发送完**ACK**后直接关闭的话，如果发生了报文段丢失，那么两方都进不到**CLOSE**
2. 还可以防止`已失效`的报文段，客户端在发送完最后一个**ACK**，在经过2MSL,就可以是本连接持续时间内所产生的所有报文段都从网络消失。从保证在关闭连接后不会在有还在网络中滞留的报文段去骚扰服务器。

**在整个连接的建立和关闭过程中除了SYN和FIN标志，还有一个RST**
RST用于如果主机收到TCP请求后，发现IP和端口号不匹配的情况，那么服务器就会发送一个`RST`的特殊报文段给客户端

**DOS攻击**
攻击者通常在这个情况下发送大量的`TCP SYN`报文段，服务器继续响应，但是每个连接都完不成三次握手的步骤，随着`TCP SYN`逐渐变多，服务器资源被消耗完，这个攻击就是DOS的一种

抵御这种攻击的方式是`SYN cookie`


#### TCP 拥塞控制
由于出现了窗口这个东西，TCP发送报文段不是一个一个发送，就可以连续发送大量的数据包了，但是这样问题也出现了，就会出现网络复杂和网络拥堵的问题，TCP为了解决这个问题，就使用了`拥塞控制`，在面临网络拥塞时，就会遏制发送方的数据发送

拥塞控制主要有2种方法
1. 端到端的拥塞控制：因为网络层没有为运输层拥塞控制提供显示支持，所以即使网络中存在拥塞的情况，端系统也要通过网络行为来观察来推断，TCP就是使用了端到端的拥塞控制方法。也就是采用了如果超时或者三次冗余确认就会被认为网络拥塞，TCP会减小窗口的大小或者增加往返耗时来避免
2. 网络辅助的拥塞控制在网络辅助的拥塞控制中，路由器会像发送方提供关于网络中拥塞状态的反馈

当感受到了端到端的拥塞时，一般会遵循3个原则，来选择不同的算法

- 如果在报文段发送过程中丢失，那就意味着网络拥堵，此时需要适当的降低TCP发送方的效率
- 一个确认报文段指示发送方正在向接收方传递报文段，因此，当对先前未接收到确认报文段的确认到达时，能够增加发送方的速率。因为未确认的报文段到达接收方也就相当于网络不拥塞，也就相当于可以顺利到达。
- 带宽检测，带宽检测说的是TCP可以通过调节传输速率来增加/减少ACK到达的次数，如果出现丢包，就会减少传输速率，同样的，如果检测拥塞开始的出现的频率，那么就会慢慢的增加传输效率。然后慢慢是传输速率降低，再次进行探测，看看拥塞开始速率是否发生了变化

**拥塞控制算法1. 慢启动**

**拥塞控制算法2. 拥塞避免**

**拥塞控制算法3. 快速恢复**



### HTTP 工作流程

- 一次 HTTP 操作称为**事务**，其工作过程可分为四步
  - 首先客户机与服务器需要建立连接。只要单击某个超级链接，Http 工作开始
  - 建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URL），协议版本号，后面是 MIME 信息包括请求修饰符，客户机信息和可能的内容
  - 服务器接收到请求后，给予相同的响应信息，其格式为一个状态行，包含信息的协议版本号，一个成功或错误的代码，后面是 MIME 信息包含服务器信息，实体信息和可能的内容
  - 客户端接收服务器所返回的信息，通过浏览器显示在用户显示屏上，然后客户机与服务器断开连接
  - 上述过程如果有某一步出现错误，那么产生错误将返回客户端，有显示屏输出。

### 浏览器缓存机制

1. 强制缓存
expires
Cache-control
2. 协商缓存（ETag->last-modified）
ETag(If-None-Match)   Last-Modified(If-Modified-Since)

ETag(给资源打上一个md5的指纹)
为什么ETag要在Last-Modified的前面
因为Last-Modified使用的是更改时间，作为一个资源，他更改的时间，在现在的互联网时代可能改变的非常快
比如在linux,利用touch命令，每次操作文件就会更改资源的更新时间


有了`LastModified`为什么还要出一个`ETag`

“Etag 主要为了解决 Last-Modified 无法解决的一些问题：
1、一些文件也许会周期性的更改，但是他的内容并不改变(仅仅改变的修改时间)，这个时候我们并不希望客户端认为这个文件被修改了，而重新 GET；
2、某些文件修改非常频繁，比如在秒以下的时间内进行修改，(比方说 1s 内修改了 N 次)，If-Modified-Since 能检查到的粒度是 s 级的，这种修改无法判断(或者说 UNIX 记录 MTIME 只能精确到秒)；
3、某些服务器不能精确的得到文件的最后修改时间。

Last-Modified 也可以弥补 ETag 判断的缺陷，比如一些图片等静态文件的修改


#### Vary响应

`Vary` HTTP响应头决定了对于后续的请求头，如何判断是请求一个新的资源还是使用缓存的文件
当缓存服务器收到一个请求，只有当前请求和原始（缓存）的请求头跟缓存的响应头里的`Vary`都匹配，才能使用缓存的响应